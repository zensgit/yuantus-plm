name: strict-gate-recent-perf-regression

on:
  workflow_dispatch:
    inputs:
      ref:
        description: "Git ref used for strict-gate dispatch and regression checks"
        type: string
        required: false
        default: "main"
      poll_interval_sec:
        description: "Polling interval in seconds while waiting strict-gate runs"
        type: string
        required: false
        default: "8"
      max_wait_sec:
        description: "Max wait time per strict-gate run in seconds"
        type: string
        required: false
        default: "1800"
      regression_attempts:
        description: "Retry attempts for regression script when transient failures occur"
        type: string
        required: false
        default: "2"
      regression_retry_delay_sec:
        description: "Retry backoff delay in seconds between regression attempts"
        type: string
        required: false
        default: "15"
      success_fail_if_no_metrics:
        description: "Valid-case recent_perf_fail_if_no_metrics for regression script (true|false)"
        type: string
        required: false
        default: "false"
  schedule:
    # Weekly Tue 05:00 UTC: regression health check for strict-gate recent perf audit path.
    - cron: "0 5 * * 2"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

jobs:
  recent_perf_regression:
    name: recent_perf_regression
    runs-on: ubuntu-latest
    timeout-minutes: 90
    env:
      GH_TOKEN: ${{ github.token }}
      OUTPUT_ROOT: tmp/strict-gate-artifacts/recent-perf-regression/${{ github.run_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Resolve target ref
        id: target_ref
        run: |
          set -euo pipefail
          TARGET_REF="${{ github.ref_name }}"
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            TARGET_REF="${{ github.event.inputs.ref }}"
          fi
          if [[ -z "${TARGET_REF}" ]]; then
            echo "ERROR: target ref is empty" >&2
            exit 2
          fi
          echo "target_ref=${TARGET_REF}" >> "$GITHUB_OUTPUT"

      - name: Run strict-gate recent perf audit regression
        env:
          TARGET_REF: ${{ steps.target_ref.outputs.target_ref }}
        run: |
          set -euo pipefail
          poll_interval="${{ github.event.inputs.poll_interval_sec }}"
          max_wait="${{ github.event.inputs.max_wait_sec }}"
          if [[ -z "${poll_interval}" ]]; then
            poll_interval="8"
          fi
          if [[ -z "${max_wait}" ]]; then
            max_wait="1800"
          fi
          attempts="${{ github.event.inputs.regression_attempts }}"
          retry_delay_sec="${{ github.event.inputs.regression_retry_delay_sec }}"
          success_fail_if_no_metrics="${{ github.event.inputs.success_fail_if_no_metrics }}"
          if [[ -z "${attempts}" ]]; then
            attempts="2"
          fi
          if [[ -z "${retry_delay_sec}" ]]; then
            retry_delay_sec="15"
          fi
          if [[ -z "${success_fail_if_no_metrics}" ]]; then
            success_fail_if_no_metrics="false"
          fi

          mkdir -p "${OUTPUT_ROOT}"
          write_validation_failure_summary() {
                    local reason="$1"
                    local md="${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md"
                    local json="${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json"
                    cat > "${md}" <<SUMMARY
          # Strict Gate Recent Perf Audit Regression
          
          - workflow: strict-gate.yml
          - ref: ${TARGET_REF}
          - head_sha: ${{ github.sha }}
          - result: failure
          - failure_reason: ${reason}
          
          ## Invalid Input Case (expected failure)
          
          - run_id:
          - url:
          - run conclusion:
          - Validate recent perf audit inputs:
          - Optional recent perf audit (download + trend):
          - Upload strict gate recent perf audit:
          - artifact_count: 0
          
          ## Valid Input Case (expected success)
          
          - run_id:
          - url:
          - run conclusion:
          - Validate recent perf audit inputs:
          - Optional recent perf audit (download + trend):
          - Upload strict gate recent perf audit:
          - requested recent_perf_fail_if_no_metrics: ${success_fail_if_no_metrics}
          - artifacts:
          - (none)
          - recent audit json:
          SUMMARY
          
                    REASON_VALUE="${reason}" \
                    TARGET_REF_VALUE="${TARGET_REF}" \
                    HEAD_SHA_VALUE="${{ github.sha }}" \
                    REPO_VALUE="${{ github.repository }}" \
                    SUCCESS_FAIL_IF_NO_METRICS_VALUE="${success_fail_if_no_metrics}" \
                    SUMMARY_MARKDOWN_VALUE="${md}" \
                    SUMMARY_JSON_VALUE="${json}" \
                    python3 - <<'PY'
          from __future__ import annotations
          
          import json
          import os
          from pathlib import Path
          
          payload = {
              "workflow": "strict-gate.yml",
              "ref": os.environ["TARGET_REF_VALUE"],
              "head_sha": os.environ["HEAD_SHA_VALUE"],
              "repo": os.environ["REPO_VALUE"],
              "result": "failure",
              "failure_reason": os.environ["REASON_VALUE"],
              "invalid_case": {
                  "run_id": "",
                  "url": "",
                  "conclusion": "",
                  "validate_recent_perf_audit_inputs": "",
                  "optional_recent_perf_audit": "",
                  "upload_recent_perf_audit": "",
                  "artifact_count": 0,
              },
              "valid_case": {
                  "run_id": "",
                  "url": "",
                  "conclusion": "",
                  "validate_recent_perf_audit_inputs": "",
                  "optional_recent_perf_audit": "",
                  "upload_recent_perf_audit": "",
                  "requested_fail_if_no_metrics": os.environ["SUCCESS_FAIL_IF_NO_METRICS_VALUE"] == "true",
                  "artifacts": [],
                  "recent_audit_json_path": "",
              },
              "summary_markdown": os.environ["SUMMARY_MARKDOWN_VALUE"],
          }
          
          Path(os.environ["SUMMARY_JSON_VALUE"]).write_text(
              json.dumps(payload, ensure_ascii=True, indent=2) + "\n",
              encoding="utf-8",
          )
          PY
          }
          fail_validation() {
            local reason="$1"
            echo "ERROR: ${reason}" >&2
            write_validation_failure_summary "${reason}"
            exit 2
          }

          {
            echo "run_id=${{ github.run_id }}"
            echo "target_ref=${TARGET_REF}"
            echo "attempts=${attempts}"
            echo "retry_delay_sec=${retry_delay_sec}"
            echo "poll_interval_sec=${poll_interval}"
            echo "max_wait_sec=${max_wait}"
            echo "success_fail_if_no_metrics=${success_fail_if_no_metrics}"
          } > "${OUTPUT_ROOT}/REGRESSION_RUN_CONTEXT.txt"

          if ! [[ "${attempts}" =~ ^[0-9]+$ ]] || [[ "${attempts}" -lt 1 ]] || [[ "${attempts}" -gt 3 ]]; then
            fail_validation "regression_attempts must be an integer in [1,3] (got: ${attempts})"
          fi
          if ! [[ "${retry_delay_sec}" =~ ^[0-9]+$ ]] || [[ "${retry_delay_sec}" -lt 0 ]]; then
            fail_validation "regression_retry_delay_sec must be a non-negative integer (got: ${retry_delay_sec})"
          fi
          if [[ "${success_fail_if_no_metrics}" != "true" && "${success_fail_if_no_metrics}" != "false" ]]; then
            fail_validation "success_fail_if_no_metrics must be true|false (got: ${success_fail_if_no_metrics})"
          fi

          success=0
          for attempt in $(seq 1 "${attempts}"); do
            attempt_dir="${OUTPUT_ROOT}/attempt-${attempt}"
            mkdir -p "${attempt_dir}"
            echo "==> strict-gate recent perf regression attempt ${attempt}/${attempts}"
            if bash scripts/strict_gate_recent_perf_audit_regression.sh \
              --workflow strict-gate.yml \
              --repo "${{ github.repository }}" \
              --ref "${TARGET_REF}" \
              --poll-interval-sec "${poll_interval}" \
              --max-wait-sec "${max_wait}" \
              --success-fail-if-no-metrics "${success_fail_if_no_metrics}" \
              --out-dir "${attempt_dir}" \
              --summary-json "${attempt_dir}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json"; then
              attempt_rc=0
            else
              attempt_rc=$?
            fi

            if [[ -f "${attempt_dir}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md" ]]; then
              cp -f "${attempt_dir}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md" "${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md"
            fi
            if [[ -f "${attempt_dir}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json" ]]; then
              cp -f "${attempt_dir}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json" "${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json"
            fi

            if [[ "${attempt_rc}" -eq 0 ]]; then
              success=1
              break
            fi
            if [[ "${attempt}" -lt "${attempts}" ]]; then
              echo "Attempt ${attempt} failed; sleep ${retry_delay_sec}s before retry..."
              sleep "${retry_delay_sec}"
            fi
          done

          if [[ "${success}" != "1" ]]; then
            echo "ERROR: strict-gate recent perf regression failed after ${attempts} attempts" >&2
            exit 1
          fi

      - name: Write regression summary to job summary
        if: always()
        run: |
          set -euo pipefail
          md="${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md"
          json="${OUTPUT_ROOT}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json"
          if [[ -f "${md}" ]]; then
            cat "${md}" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "strict-gate regression markdown missing: ${md}" >> "$GITHUB_STEP_SUMMARY"
          fi
          if [[ -f "${json}" ]]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "JSON summary: \`${json}\`" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload strict-gate recent perf regression evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: strict-gate-recent-perf-regression
          path: |
            tmp/strict-gate-artifacts/recent-perf-regression/${{ github.run_id }}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.md
            tmp/strict-gate-artifacts/recent-perf-regression/${{ github.run_id }}/STRICT_GATE_RECENT_PERF_AUDIT_REGRESSION.json
          if-no-files-found: warn
          retention-days: 14

      - name: Upload strict-gate recent perf regression raw outputs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: strict-gate-recent-perf-regression-raw
          path: tmp/strict-gate-artifacts/recent-perf-regression/${{ github.run_id }}
          if-no-files-found: warn
          retention-days: 14
